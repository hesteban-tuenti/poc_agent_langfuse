# Langfuse Tracing POC for Agentic AI Solutions

A proof-of-concept (POC) demonstrating how to implement and test traces in an agentic AI architecture using **Langfuse** and how to validate the information within the traces. This project showcases hierarchical tracing across multi-step agent interactions with tool calling.

## ğŸ¯ Project Overview

This POC demonstrates:
- âœ… **Hierarchical trace capture** across agent sessions, LLM calls, and tool executions
- âœ… **OpenAI function calling** integration with simple, functional tools
- âœ… **Langfuse Cloud** integration for trace visualization and analysis
- âœ… **Multiple test scenarios** covering single-tool, multi-tool, and reasoning-only interactions
- âœ… **Trace metadata** including user IDs, session IDs, and custom tags

## ğŸ—ï¸ Architecture

```
User Query
    â†“
run_agent() [@observe - Top Level Trace]
    â†“
    â”œâ”€â†’ call_llm() [@observe - LLM Interaction]
    â”‚       â†“
    â”‚   OpenAI API (gpt-4o-mini)
    â”‚
    â”œâ”€â†’ execute_tool() [@observe - Tool Execution]
    â”‚       â†“
    â”‚   Tool Functions (calculate, get_current_time, get_random_fact)
    â”‚
    â””â”€â†’ Final Answer + Trace URL
```

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- Langfuse Cloud account ([Sign up here](https://cloud.langfuse.com))

## ğŸš€ Setup Instructions

### 1. Clone and Navigate to the Project

```bash
cd <WORKSPACE>/agent-trace-langfuse
```

### 2. Create a Virtual Environment (Recommended)

```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

Copy the example environment file:

```bash
cp .env.example .env
```

Edit `.env` with your actual API keys:

```bash
# OpenAI API Key
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-actual-openai-key

# Langfuse API Keys
# Sign up and get your keys from: https://cloud.langfuse.com
LANGFUSE_PUBLIC_KEY=pk-lf-your-actual-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-actual-secret-key
LANGFUSE_HOST=https://cloud.langfuse.com
```


## ğŸ§ª Running the Tests

### Run All Test Scenarios with Unittest

```bash
# Run all tests with live API calls
python test_poc_agent_langfuse.py

# Or using unittest directly
python -m unittest test_poc_agent_langfuse.py -v
```

### Test Modes

The test suite supports two modes via the `USE_MOCK` environment variable:

```bash
# Live mode (default) - Uses real OpenAI and Langfuse API calls
USE_MOCK=false python test_poc_agent_langfuse.py

# Mock mode - Uses predefined responses, no API calls but mocked LLM results are needed 
USE_MOCK=true python test_poc_agent_langfuse.py
```

### Test Scenarios Covered

1. **test_01_single_tool_usage** - Simple calculation (25 Ã— 4)
   - Validates: 1 LLM call, 1 tool execution (`calculate`)
   
2. **test_02_multi_tool_usage** - Time + calculation (current time + 100 Ã· 5)
   - Validates: 2+ LLM calls, 2 tool executions (`get_current_time`, `calculate`)
   
3. **test_03_reasoning_without_tools** - Pure reasoning (explain quantum computing)
   - Validates: 1+ LLM call, 0 tool executions

### Trace Inspection

Each test automatically inspects traces using `inspect_trace()` which:
- Waits for traces to be available in Langfuse (up to 30 seconds)
- Extracts and categorizes observations by type (`AGENT`, `TOOL`)
- Validates expected LLM calls and tool executions
- Prints trace structure and URLs for manual inspection

### Run Specific Tests

```bash
# Run a single test
python -m unittest test_poc_agent_langfuse.TestLangfuseTracing.test_01_single_tool_usage

# Run with mock mode
USE_MOCK=true python -m unittest test_poc_agent_langfuse.TestLangfuseTracing.test_01_single_tool_usage
```

### Quick Agent Test

Test the agent directly without unittest:

```bash
python poc_agent.py
```

## ğŸ“Š Viewing Traces in Langfuse

After running tests:

1. Open [Langfuse Cloud Dashboard](https://cloud.langfuse.com)
2. Navigate to **"Traces"** in the sidebar
3. You'll see your test runs with metadata:
   - User ID: `test_user_1`, `test_user_2`, etc.
   - Session IDs: `test_single_tool`, `test_multi_tool`, etc.
   - Tags: `poc`, `agent`, `openai`

4. Click on any trace to inspect:
   - **Hierarchical structure** of the agent execution
   - **LLM inputs/outputs** at each step
   - **Tool calls** with arguments and results
   - **Timing and latency** for each operation
   - **Token usage** and costs

### Example Trace Structure

```
ğŸ“Š run_agent (session trace)
   â”œâ”€ ğŸ¤– call_llm (initial user query)
   â”œâ”€ ğŸ”§ execute_tool (calculate: "25 * 4")
   â”œâ”€ ğŸ¤– call_llm (process tool result)
   â””â”€ âœ… Final Answer: "100"
```

## ğŸ“ Project Structure

```
agent-trace-langfuse/
â”œâ”€â”€ .env                          # Environment variables (not in git)
â”œâ”€â”€ .env.example                  # Template for environment variables
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # This file
â”‚
â”œâ”€â”€ tools.py                      # Tool definitions and implementations
â”‚   â”œâ”€â”€ calculate()              # Mathematical expression evaluator
â”‚   â”œâ”€â”€ get_current_time()       # Current datetime retriever
â”‚   â”œâ”€â”€ get_random_fact()        # Random fact generator
â”‚   â””â”€â”€ TOOL_DEFINITIONS         # OpenAI function calling schemas
â”‚
â”œâ”€â”€ poc_agent.py                  # Main agent implementation
â”‚   â”œâ”€â”€ call_llm()               # LLM interaction with tracing
â”‚   â”œâ”€â”€ execute_tool()           # Tool execution with tracing
â”‚   â””â”€â”€ run_agent()              # Top-level agent loop with tracing
â”‚
â””â”€â”€ test_traces.py                # Test scenarios
    â”œâ”€â”€ test_single_tool_usage()
    â”œâ”€â”€ test_multi_tool_usage()
    â”œâ”€â”€ test_reasoning_without_tools()
    â””â”€â”€ test_complex_multi_step()
```

## ğŸ”§ Tools Available

### 1. `calculate(expression: str)`
Evaluates mathematical expressions.

**Example:**
```python
calculate("25 * 4")  # Returns: 100
calculate("(100 + 50) / 2")  # Returns: 75
```

### 2. `get_current_time(timezone: str = "UTC")`
Returns current date and time in multiple formats.

**Example:**
```python
get_current_time()  
# Returns: ISO datetime, date, time, formatted string
```

### 3. `get_random_fact(category: str = "general")`
Returns a random fact from predefined categories.

**Categories:** `general`, `science`, `history`, `tech`

**Example:**
```python
get_random_fact("science")
# Returns: A random science fact
```


## ğŸ”„ Next Steps / Enhancements

This POC can be extended with:

- âœ¨ **More complex tools** (API calls, database queries, file operations)
- âœ¨ **Error handling traces** (failed tool calls, API errors, timeouts)
- âœ¨ **Nested agent calls** (agents calling other agents)
- âœ¨ **LiteLLM integration** (multi-provider support)
- âœ¨ **Async execution** (parallel tool calls, improved performance)
- âœ¨ **Evaluation metrics** (response quality, tool selection accuracy)
- âœ¨ **Cost tracking** (per-session cost analysis in Langfuse)
- âœ¨ **A/B testing** (compare different prompts or models)

## ğŸ“š Resources

- [Langfuse Documentation](https://langfuse.com/docs)
- [Langfuse Python SDK](https://langfuse.com/docs/sdk/python)
- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
- [OpenAI Python SDK](https://github.com/openai/openai-python)

